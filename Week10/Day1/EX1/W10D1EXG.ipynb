{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkmJK6VfLeDyv9NeGBF5rA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arquansa/PSTB-exercises/blob/main/W10/D1/EX1/W10D1EXG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises XP Gold\n",
        "Last Updated: May 6th, 2025\n",
        "\n",
        "👩‍🏫 👩🏿‍🏫 What You’ll learn\n",
        "In this XP track, you’ll learn how to:\n",
        "\n",
        "Craft precise, effective prompts for complex tasks.\n",
        "Debug and refine chain-of-thought (CoT) reasoning.\n",
        "Select the best prompt pattern for real-world applications.\n",
        "Reduce hallucinations through multi-path prompting.\n",
        "Design prompt workflows and chains with conditional logic.\n",
        "Mitigate bias in language models using role-based prompts.\n",
        "Simulate memory in LLMs to improve user experience.\n",
        "\n",
        "\n",
        "🛠️ What you will create\n",
        "You’ll build and test:\n",
        "\n",
        "Corrected and optimized chain-of-thought prompts.\n",
        "Domain-specific prompt patterns for real use cases.\n",
        "Multi-step prompting pipelines with conditional logic.\n",
        "Fair and inclusive prompts using role prompting.\n",
        "Conversational agents with simulated memory and personalized outputs.\n",
        "\n",
        "\n",
        "Exercise 1: Debug a Faulty Chain-of-Thought\n",
        "Goal: Practice constructing and improving Chain-of-Thought prompts by spotting flaws in reasoning and refining step-by-step outputs.\n",
        "\n",
        "\n",
        "Prompt Task:\n",
        "\n",
        "The following Chain-of-Thought prompt was used to solve a problem, but it produced an incorrect answer.\n",
        "Your job is to identify where the logic breaks, rewrite the CoT, and correct the final answer.\n",
        "\n",
        "\n",
        "Original Prompt:\n",
        "\n",
        "A shop sells pencils at $0.75 each. If Alice buys 6 pencils and pays with a $5 bill, how much change does she get? Let’s solve this step-by-step.\n",
        "6 pencils × $0.75 = $4.75\n",
        "$5.00 - $4.75 = $0.50\n",
        "The change is $0.50.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Find the mistake in the reasoning.\n",
        "Rewrite the prompt with the correct Chain-of-Thought.\n",
        "Provide the correct answer.\n",
        "\n",
        "\n",
        "Exercise 2: Choose the Right Prompt Pattern\n",
        "Goal: Select the optimal prompting strategy for a real-world NLP use case and explain your choice.\n",
        "\n",
        "\n",
        "\n",
        "Scenario:\n",
        "\n",
        "You’re building a customer support chatbot. One of its tasks is to categorize customer messages into one of the following classes:\n",
        "\n",
        "Billing Issue\n",
        "Technical Support\n",
        "Account Access\n",
        "Other\n",
        "\n",
        "\n",
        "Your Task:\n",
        "\n",
        "Choose the best prompting pattern (e.g., Zero-Shot, Few-Shot, IAP, LoT, etc.) for this use case.\n",
        "Write a complete prompt example using that pattern.\n",
        "Justify why your choice is most appropriate, considering ambiguity, consistency, and model generalization.\n",
        "\n",
        "\n",
        "Exercise 3: Use AlignedCoT to Compare Reasoning Paths\n",
        "Goal: Explore how Aligned Chain-of-Thought (AlignedCoT) reduces hallucination and improves answer reliability.\n",
        "\n",
        "\n",
        "\n",
        "Problem:\n",
        "\n",
        "A gardener has 3 types of flower pots:\n",
        "\n",
        "Small pots cost $2 each\n",
        "Medium pots cost $4 each\n",
        "Large pots cost $6 each\n",
        "She buys 2 small, 3 medium, and 1 large pot.\n",
        "\n",
        "\n",
        "What is the total cost?\n",
        "\n",
        "Your Task:\n",
        "\n",
        "Construct an AlignedCoT prompt that asks the model to reason using at least two distinct paths.\n",
        "Include a comparison step where the model selects the consistent or most logical answer.\n",
        "Ensure each reasoning path uses a different structure, order, or framing.\n",
        "\n",
        "\n",
        "Exercise 4: Design a Multi-Step Document Pipeline\n",
        "Goal: Apply prompt chaining and conditional logic to automate a real-world LLM workflow.\n",
        "\n",
        "\n",
        "Scenario:\n",
        "\n",
        "You’ve been asked to design a pipeline to process incoming academic research papers.\n",
        "\n",
        "The system must:\n",
        "\n",
        "Identify the domain (e.g., biology, physics, computer science)\n",
        "Extract the main contributions from the abstract\n",
        "Generate a follow-up research question\n",
        "\n",
        "\n",
        "Your Task:\n",
        "\n",
        "Break down this task into three distinct prompt stages.\n",
        "Write a sample prompt template for each stage.\n",
        "Identify where conditional logic or context chaining would be useful in your pipeline.\n",
        "\n",
        "\n",
        "Exercise 5: Role Prompting to Reduce Bias\n",
        "Goal: Use role-based prompting to reduce assumptions and increase fairness in model responses.\n",
        "\n",
        "Scenario:\n",
        "\n",
        "You’re building a recommendation system to suggest career paths based on a user’s skills and interests.\n",
        "However, you want to avoid generating biased suggestions that reflect stereotypes (e.g., recommending nursing only to women, engineering only to men).\n",
        "\n",
        "\n",
        "\n",
        "Your Task:\n",
        "\n",
        "1. Write two versions of a prompt:\n",
        "\n",
        "One basic version that may lead to biased results\n",
        "One revised version using role prompting to reduce bias\n",
        "2. Explain how the role prompt improves the fairness of the recommendation.\n",
        "\n",
        "\n",
        "\n",
        "Exercise 6: Build a Conversational Agent with Context Memory\n",
        "Goal: Simulate memory in a chatbot using structured context chaining.\n",
        "\n",
        "\n",
        "Scenario:\n",
        "You are creating a virtual health coach. Users can chat with it about sleep habits, diet, and exercise.\n",
        "To make the conversation feel continuous, the bot should remember user preferences and previous advice given.\n",
        "\n",
        "\n",
        "Your Task:\n",
        "\n",
        "Choose one memory technique (e.g., prior message passing, structured history, or vector store retrieval).\n",
        "Write an example of how you’d structure the context from past interactions.\n",
        "Create a new prompt that incorporates this context to make the next response coherent and personalized.\n"
      ],
      "metadata": {
        "id": "90Gr8OUXr3f-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: Debug a Faulty Chain-of-Thought\n",
        "Goal: Practice constructing and improving Chain-of-Thought prompts by spotting flaws in reasoning and refining step-by-step outputs.\n",
        "\n",
        "Prompt Task:\n",
        "\n",
        "The following Chain-of-Thought prompt was used to solve a problem, but it produced an incorrect answer. Your job is to identify where the logic breaks, rewrite the CoT, and correct the final answer.\n",
        "\n",
        "Original Prompt:\n",
        "\n",
        "A shop sells pencils at  0.75each.IfAlicebuys6pencilsandpayswitha 5 bill, how much change does she get? Let’s solve this step-by-step. 6 pencils ×  0.75= 4.75  5.00− 4.75 =  0.50Thechangeis 0.50.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Find the mistake in the reasoning. Rewrite the prompt with the correct Chain-of-Thought. Provide the correct answer."
      ],
      "metadata": {
        "id": "dXNl8WwVsmLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original Prompt:\n",
        "\n",
        "A shop sells pencils at  0.75each.IfAlicebuys6pencilsandpayswitha 5 bill, how much change does she get? Let’s solve this step-by-step. 6 pencils ×  0.75= 4.75  5.00− 4.75 =  0.50Thechangeis 0.50.\n"
      ],
      "metadata": {
        "id": "XwJiAjZlvlsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shop sells 6 pencils at 0.75 each with a 5 bill => 6 x 0.75 = 4.50 => 5.00 - 4.50 = 0.50 ==> The change is 0.50\n",
        "\n",
        "Corrected Prompt:\n",
        "\n",
        "A shop sells pencils at  0.75each.IfAlicebuys6pencilsandpayswitha 5 bill, how much change does she get? Let’s solve this step-by-step. 6 pencils ×  0.75= 4.50  5.00− 4.5. =  0.50 Thechange is 0.50.\n"
      ],
      "metadata": {
        "id": "WKsRrYYds1yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: Choose the Right Prompt Pattern\n",
        "Goal: Select the optimal prompting strategy for a real-world NLP use case and explain your choice.\n",
        "\n",
        "Scenario:\n",
        "\n",
        "You’re building a customer support chatbot. One of its tasks is to categorize customer messages into one of the following classes:\n",
        "\n",
        "Billing Issue Technical Support Account Access Other\n",
        "\n",
        "Your Task:\n",
        "\n",
        "Choose the best prompting pattern (e.g., Zero-Shot, Few-Shot, IAP, LoT, etc.) for this use case. Write a complete prompt example using that pattern. Justify why your choice is most appropriate, considering ambiguity, consistency, and model generalization."
      ],
      "metadata": {
        "id": "9ORhyRwhs1w8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Pattern: Few-Shot Prompting\n",
        "✅ Prompt Example:\n",
        "\n",
        "You are a customer support assistant. Categorize the following customer message into one of these categories:\n",
        "\n",
        "Billing Issue\n",
        "\n",
        "Technical Support\n",
        "\n",
        "Account Access\n",
        "\n",
        "Other\n",
        "\n",
        "Examples:\n",
        "Message: “I was charged twice this month.”\n",
        "Category: Billing Issue\n",
        "\n",
        "Message: “I forgot my password and can’t log in.”\n",
        "Category: Account Access\n",
        "\n",
        "Message: “The app crashes when I try to open it.”\n",
        "Category: Technical Support\n",
        "\n",
        "Now classify:\n",
        "Message: “I want to delete my account permanently.”\n",
        "Category: Account Access\n",
        "\n",
        "Few-Shot because:\n",
        "- It provides grounding through examples.\n",
        "- It hHelps disambiguate similar intents.\n",
        "- it balances generalization and precision for edge cases."
      ],
      "metadata": {
        "id": "VBw51cvms1sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3: Use AlignedCoT to Compare Reasoning Paths\n",
        "\n",
        "Goal: Explore how Aligned Chain-of-Thought (AlignedCoT) reduces hallucination and improves answer reliability.\n",
        "\n",
        "Problem:\n",
        "\n",
        "A gardener has 3 types of flower pots:\n",
        "\n",
        "Small pots cost  2eachMediumpotscost 4 each Large pots cost $6 each She buys 2 small, 3 medium, and 1 large pot.\n",
        "\n",
        "What is the total cost?\n",
        "\n",
        "Your Task:\n",
        "\n",
        "Construct an AlignedCoT prompt that asks the model to reason using at least two distinct paths. Include a comparison step where the model selects the consistent or most logical answer. Ensure each reasoning path uses a different structure, order, or framing."
      ],
      "metadata": {
        "id": "x6l3-8Zas1qu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A gardener buys:\n",
        "\n",
        "2 small pots at $2 each\n",
        "\n",
        "3 medium pots at $4 each\n",
        "\n",
        "1 large pot at $6\n",
        "\n",
        "Finding solution, using two methods and comparing the results.\n",
        "\n",
        "Path 1: Grouped by size\n",
        "\n",
        "Small: 2 × $2 = $4\n",
        "\n",
        "Medium: 3 × $4 = $12\n",
        "\n",
        "Large: 1 × $6 = $6\n",
        "\n",
        "Total: $4 + $12 + $6 = $22\n",
        "\n",
        "Path 2: List of all items\n",
        "\n",
        "Item 1 (small): $2\n",
        "\n",
        "Item 2 (small): $2\n",
        "\n",
        "Item 3 (medium): $4\n",
        "\n",
        "Item 4 (medium): $4\n",
        "\n",
        "Item 5 (medium): $4\n",
        "\n",
        "Item 6 (large): $6\n",
        "\n",
        "Total: $2 + $2 + $4 + $4 + $4 + $6 = $22\n",
        "\n",
        "Both methods agree: Total cost is $22"
      ],
      "metadata": {
        "id": "q0iD-NsXs1mJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4: Design a Multi-Step Document Pipeline\n",
        "\n",
        "Goal: Apply prompt chaining and conditional logic to automate a real-world LLM workflow.\n",
        "\n",
        "Scenario:\n",
        "\n",
        "You’ve been asked to design a pipeline to process incoming academic research papers.\n",
        "\n",
        "The system must:\n",
        "\n",
        "- Identify the domain (e.g., biology, physics, computer science)\n",
        "- Extract the main contributions from the abstract\n",
        "- Generate a follow-up research question\n",
        "\n",
        "Your Task:\n",
        "- Break down this task into three distinct prompt stages.\n",
        "- Write a sample prompt template for each stage.\n",
        "- Identify where conditional logic or context chaining would be useful in your pipeline."
      ],
      "metadata": {
        "id": "p5sFx7VBs1fo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline Breakdown:\n",
        "\n",
        "Stage 1: Domain Identification\n",
        "\n",
        "Prompt:\n",
        "\n",
        "Analyze the following academic paper abstract. What is its primary research domain (e.g., biology, physics, computer science, etc.)?\n",
        "Abstract: [\"This paper presents a novel deep learning framework for real-time anomaly detection in network traffic, leveraging transformer architectures to improve accuracy and reduce false positives in large-scale systems.\"]\n",
        "\n",
        "Stage 2: Extract Contributions\n",
        "\n",
        "Prompt:\n",
        "\n",
        "Based on the abstract, identify the main research contribution in 1–2 bullet points.\n",
        "\n",
        "\"This paper deals with anomaly detection in network traffic thanks to deep learning, and with the improvement of large scale systems through transformer architectures leveraging.\"\n",
        "\n",
        "Stage 3: Generate Research Question\n",
        "\n",
        "Prompt:\n",
        "\n",
        "Based on the contributions above, suggest one logical follow-up research question that a future paper could explore.\n",
        "\n",
        "*\"A logical follow research question would be to try and find a means to make those improvements while avoiding an increase of consumption costs in the process.\"*\n",
        "\n",
        "Where to Use Conditional Logic:\n",
        "\n",
        "If the domain is Computer Science, follow-up prompts can include keywords like \"algorithm\" or \"efficiency.\"\n",
        "\n",
        "If the contribution is unclear, prompt the model to say, \"Contribution unclear — more data needed.\""
      ],
      "metadata": {
        "id": "5rrno80ZuROv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lIfgt1L7s1d_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 5: Role Prompting to Reduce Bias\n",
        "\n",
        "Goal: Use role-based prompting to reduce assumptions and increase fairness in model responses.\n",
        "\n",
        "Scenario:\n",
        "\n",
        "You’re building a recommendation system to suggest career paths based on a user’s skills and interests. However, you want to avoid generating biased suggestions that reflect stereotypes (e.g., recommending nursing only to women, engineering only to men).\n",
        "\n",
        "Your Task:\n",
        "\n",
        "Write two versions of a prompt:\n",
        "One basic version that may lead to biased results One revised version using role prompting to reduce bias\n",
        "\n",
        "Explain how the role prompt improves the fairness of the recommendation."
      ],
      "metadata": {
        "id": "bba7S2q0s1ZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biased Prompt Example:\n",
        "\n",
        "Suggest a career path for this user:\n",
        "- Gender: Female\n",
        "- Interests: Science, helping others\n",
        "\n",
        "Bias-Reduced Prompt with Role Prompting:\n",
        "\n",
        "You are a career guidance counselor trained to provide fair, inclusive advice.\n",
        "Suggest 3 career paths based solely on the user’s skills and interests, not gender or background.\n",
        "\n",
        "User Profile:\n",
        "- Interests: Science, helping others\n",
        "- Recommend neutral, inclusive paths.\n",
        "\n",
        "How Role Prompting Helps:\n",
        "- Reframes the model’s role to prioritize fairness.\n",
        "- Encourages it to avoid stereotypes by grounding in values (e.g., inclusive counseling)."
      ],
      "metadata": {
        "id": "KXcBRD24s1Xe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 6: Build a Conversational Agent with Context Memory\n",
        "\n",
        "Goal: Simulate memory in a chatbot using structured context chaining.\n",
        "\n",
        "Scenario: You are creating a virtual health coach. Users can chat with it about sleep habits, diet, and exercise. To make the conversation feel continuous, the bot should remember user preferences and previous advice given.\n",
        "\n",
        "Your Task:\n",
        "\n",
        "Choose one memory technique (e.g., prior message passing, structured history, or vector store retrieval). Write an example of how you’d structure the context from past interactions. Create a new prompt that incorporates this context to make the next response coherent and personalized."
      ],
      "metadata": {
        "id": "Eg0EspZjs1Lm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Structured Context Example:\n",
        "\n",
        "Conversation History Snapshot:"
      ],
      "metadata": {
        "id": "1Cy6cMHEK6DC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "User prefers low-carb meals.\n",
        "Sleeps 6 hours on average, wants to improve sleep.\n",
        "Exercises 3x/week, wants new workout ideas.\n"
      ],
      "metadata": {
        "id": "BLf-XSH5LAoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Using This Context:\n",
        "\n",
        "You are a virtual health coach.\n",
        "The user sleeps 6 hours/night and wants to improve that.\n",
        "Provide 2 science-based tips to increase sleep duration, and reference their existing low-carb diet and 3x/week workout routine for personalized advice."
      ],
      "metadata": {
        "id": "DsRIMB76s0xU"
      }
    }
  ]
}