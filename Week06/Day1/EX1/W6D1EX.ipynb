{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPqqINOHFhDNwGbKKyLG7n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arquansa/PSTB-exercises/blob/main/Week06/Day1/EX1/W6D1EX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercises XP\n",
        "Last Updated: June 20th, 2025\n",
        "\n",
        "üë©‚Äçüè´ üë©üèø‚Äçüè´ What You‚Äôll learn\n",
        "The fundamentals of deep learning and neural networks.\n",
        "How to build and train simple neural networks using TensorFlow/Keras.\n",
        "The concepts of forward and backward propagation.\n",
        "How to visualize and interpret model predictions.\n",
        "\n",
        "\n",
        "üõ†Ô∏è What you will create\n",
        "A simple perceptron-based decision system.\n",
        "A neural network for classifying handwritten digits from the MNIST dataset.\n",
        "A forward propagation calculation for predicting house prices.\n",
        "A Python implementation of forward and backward propagation.\n",
        "Visualizations of predictions made by a neural network on the MNIST dataset.\n",
        "\n",
        "\n",
        "üåü Exercise 1 : Small Quizz\n",
        "What is the key difference between traditional machine learning and deep learning?\n",
        "How do artificial neural networks (ANNs) mimic the human brain?\n",
        "Why does deep learning perform better on large datasets compared to traditional machine learning?\n",
        "What are some challenges of deep learning, and how can they be addressed?\n",
        "What is feature engineering, and why is it not needed in deep learning?\n",
        "What role do hidden layers play in a deep learning model?\n",
        "In an artificial neural network (ANN), what is the function of an activation function?\n",
        "\n",
        "\n",
        "üåü Exercise 2 : Building a Simple Perceptron Decision System\n",
        "You will manually create a simple perceptron-based decision system to determine whether you should go outside based on two inputs:\n",
        "\n",
        "Temperature (¬∞F)\n",
        "Rainy (Yes = 1, No = 0)\n",
        "You will assign weights, compute the weighted sum, apply an activation function, and determine the final decision.\n",
        "\n",
        "Temperature weight = 0.6\n",
        "Rain weight = 0.4\n",
        "Bias = 2\n",
        "Compute the weighted sum using the formula:\n",
        "\n",
        "Weighted Sum=(Temperature√ó0.6)+(Rain√ó0.4)+Bias\n",
        "Weighted Sum=(Temperature√ó0.6)+(Rain√ó0.4)+Bias\n",
        "Apply a Step Activation Function:\n",
        "\n",
        "If Weighted Sum > 20, output 1 (Yes, go outside)\n",
        "If Weighted Sum ‚â§ 20, output 0 (No, stay inside)\n",
        "1. Calculate the output for the following conditions:\n",
        "\n",
        "Case 1: Temperature = 70¬∞F, Rain = 0 (No)\n",
        "Case 2: Temperature = 50¬∞F, Rain = 1 (Yes)\n",
        "2. Interpret the results: Did the perceptron suggest going outside in both cases? Why or why not?\n",
        "\n",
        "\n",
        "\n",
        "üåü Exercise 3 : Building a Simple Neural Network with TensorFlow/Keras\n",
        "Build a simple neural network using TensorFlow/Keras to classify handwritten digits from the MNIST dataset. The network should have:\n",
        "\n",
        "One input layer.\n",
        "One hidden layer with 128 neurons and ReLU activation.\n",
        "One output layer with 10 neurons (for 10 classes) and softmax activation.\n",
        "Steps:\n",
        "\n",
        "1. Import TensorFlow and other necessary modules such as layers, models, and utility functions from tensorflow.keras\n",
        "2. Load the MNIST Dataset\n",
        "3. Normalize the Data by scaling the pixel values of the images to the range [0, 1] by dividing by 255.0.\n",
        "4. One-Hot Encode the Labels by converting the digit labels (0‚Äì9) into one-hot encoded vectors.\n",
        "5. To build the Neural Network Model, create a sequential model with the following architecture:\n",
        "\n",
        "A Flatten layer to convert each 28x28 image into a 1D vector.\n",
        "A Dense hidden layer with 128 neurons and ReLU activation.\n",
        "An output Dense layer with 10 neurons and softmax activation (for the 10 classes).\n",
        "6. Compile the model with the following settings:\n",
        "\n",
        "Optimizer: ‚Äòadam‚Äô\n",
        "Loss function: ‚Äòcategorical_crossentropy‚Äô\n",
        "Metrics: [‚Äòaccuracy‚Äô]\n",
        "7. Train the Model and Evaluate it on the test dataset.\n",
        "\n",
        "Dataset: The MNIST dataset is included in TensorFlow/Keras and can be loaded using:\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "\n",
        "üåü Exercise 4 : Forward Propagation Calculation\n",
        "In this exercise, you will manually compute the forward propagation of a simple neural network that predicts house prices based on:\n",
        "\n",
        "Square Footage (x‚ÇÅ)\n",
        "Number of Bedrooms (x‚ÇÇ)\n",
        "We will calculate the output using the following given values:\n",
        "\n",
        "Input Values:\n",
        "    x‚ÇÅ = 2000 (Square Footage)\n",
        "    x‚ÇÇ = 3 (Number of Bedrooms)\n",
        "Initial Weights:\n",
        "    w‚ÇÅ = 0.5 (Weight for Square Footage)\n",
        "    w‚ÇÇ = 0.7 (Weight for Bedrooms)\n",
        "Bias: b = 50,000\n",
        "Activation Function: ReLU (Rectified Linear Unit)\n",
        "Calculate the output value ‚Äúz‚Äù before activation.\n",
        "Apply the ReLU function to compute the final prediction.\n",
        "Interpret the result: What is the predicted house price?\n",
        "\n",
        "\n",
        "üåü Exercise 5(optional) : Implementing Forward and Backward Propagation in Python\n",
        "You will code a simple neural network that performs forward propagation and backpropagation for a regression problem (predicting exam scores based on study hours).\n",
        "\n",
        "import numpy as np\n",
        "\n",
        " Initialize input data (features)\n",
        "x = np.array([4, 80])  # 4 hours studied, previous test score: 80\n",
        "\n",
        " Initialize weights and bias\n",
        "w = np.array([0.6, 0.3])  # Initial weights\n",
        "b = 10  # Initial bias\n",
        "\n",
        " Forward Propagation\n",
        "def forward_propagation(x, w, b):\n",
        "    z = np.dot(x, w) + b  # Weighted sum\n",
        "    return z  # Linear activation (No ReLU here, it's a regression task)\n",
        "\n",
        " Compute prediction\n",
        "y_pred = forward_propagation(x, w, b)\n",
        "y_true = 85  # Actual exam score\n",
        "\n",
        " Compute Loss (Mean Squared Error)\n",
        "loss = 0.5 * (y_true - y_pred) ** 2\n",
        "\n",
        " Compute Gradients\n",
        "grad_w = -(y_true - y_pred) * x  # Partial derivatives with respect to weights\n",
        "grad_b = -(y_true - y_pred)  # Partial derivative with respect to bias\n",
        "\n",
        " Update Weights and Bias\n",
        "learning_rate = 0.01\n",
        "w_new = w - learning_rate * grad_w\n",
        "b_new = b - learning_rate * grad_b\n",
        "\n",
        " Print Results\n",
        "print(\"Initial Prediction:\", y_pred)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Updated Weights:\", w_new)\n",
        "print(\"Updated Bias:\", b_new)\n",
        "\n",
        "\n",
        "Run the code and observe how the weights and bias update.\n",
        "Explain why updating weights using gradient descent reduces the error.\n",
        "Modify the initial weights or learning rate and see how it affects learning.\n",
        "\n",
        "\n",
        "üåü Exercise 6(optional) : Visualizing Predictions on the MNIST Dataset\n",
        "Train a simple neural network using TensorFlow/Keras on the MNIST dataset. After training, visualize some of the predictions made by the model.\n",
        "\n",
        "Dataset: The MNIST dataset is included in TensorFlow/Keras.\n",
        "\n",
        "Here are the steps for this exercise :\n",
        "\n",
        "0. Import Required Libraries : Import TensorFlow, NumPy, Matplotlib, and other necessary Keras modules.\n",
        "1. Load the MNIST dataset\n",
        "2. Normalize the data : Scale the pixel values to the range [0, 1].\n",
        "3. One-hot encode the labels : Convert the class labels (digits 0‚Äì9) into one-hot encoded vectors.\n",
        "4. Build the model : Create a model with a Flatten layer to convert each image to a vector, a dense layer with 128 neurons and ReLU activation and an output Dense layer with 10 neurons and softmax activation.\n",
        "5. Compile the model using the following settings:\n",
        "\n",
        "Optimizer: ‚Äòadam‚Äô\n",
        "Loss: ‚Äòcategorical_crossentropy‚Äô\n",
        "Metric: ‚Äòaccuracy‚Äô\n",
        "6. Fit the model on the training data\n",
        "7. Make predictions : Use the trained model to predict the labels of the test images\n",
        "8. Visualize some predictions : Display a few test images alongside the predicted labels using Matplotlib\n",
        "\n"
      ],
      "metadata": {
        "id": "gjpiRLawu61I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üåü Exercise 1 : Small Quizz What is the key difference between traditional machine learning and deep learning? How do artificial neural networks (ANNs) mimic the human brain? Why does deep learning perform better on large datasets compared to traditional machine learning? What are some challenges of deep learning, and how can they be addressed? What is feature engineering, and why is it not needed in deep learning? What role do hidden layers play in a deep learning model? In an artificial neural network (ANN), what is the function of an activation function?"
      ],
      "metadata": {
        "id": "aeIYc2qewH69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key difference:\n",
        "1. Traditional ML needs manual feature design.\n",
        "Deep learning learns features automatically from data.\n",
        "\n",
        "2. How ANNs mimic the brain:\n",
        "They use \"neurons\" connected by \"weights\" to pass signals, like how the brain works.\n",
        "\n",
        "3. Why DL works better with big data:\n",
        "It has lots of parameters to learn, so it needs lots of data to perform well and avoid overfitting.\n",
        "\n",
        "4. Challenges of DL:\n",
        "\n",
        "- Needs a lot of data and computing power\n",
        "\n",
        "- Can overfit (learn too much from training data)\n",
        "\n",
        "- Fixes: dropout, regularization, data augmentation\n",
        "\n",
        "5. What is feature engineering?\n",
        "Picking useful data features manually. DL skips this by learning features automatically.\n",
        "\n",
        "6.Role of hidden layers:\n",
        "They find patterns and build up complex understanding step by step.\n",
        "\n",
        "7. What does an activation function do?\n",
        "Adds non-linearity so the network can learn complex things.\n",
        "(Examples: ReLU, sigmoid)"
      ],
      "metadata": {
        "id": "moomCIY51cyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üåü Exercise 2 : Building a Simple Perceptron Decision System\n",
        "\n",
        "You will manually create a simple perceptron-based decision system to determine whether you should go outside based on two inputs:\n",
        "\n",
        "Temperature (¬∞F)\n",
        "Rainy (Yes = 1, No = 0)\n",
        "\n",
        "You will assign weights, compute the weighted sum, apply an activation function, and determine the final decision.\n",
        "\n",
        "Temperature weight = 0.6\n",
        "Rain weight = 0.4\n",
        "Bias = 2\n",
        "\n",
        "Compute the weighted sum using the formula:\n",
        "\n",
        "Weighted Sum=(Temperature√ó0.6)+(Rain√ó0.4)+Bias\n",
        "Weighted Sum=(Temperature√ó0.6)+(Rain√ó0.4)+Bias\n",
        "Apply a Step Activation Function:\n",
        "\n",
        "If Weighted Sum > 20, output 1 (Yes, go outside)\n",
        "If Weighted Sum ‚â§ 20, output 0 (No, stay inside)\n",
        "\n",
        "1. Calculate the output for the following conditions:\n",
        "\n",
        "Case 1: Temperature = 70¬∞F, Rain = 0 (No)\n",
        "Case 2: Temperature = 50¬∞F, Rain = 1 (Yes)\n",
        "\n",
        "2. Interpret the results: Did the perceptron suggest going outside in both cases? Why or why not?"
      ],
      "metadata": {
        "id": "CP_lAn5TwNuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Perceptron\n",
        "Formula: Weighted¬†Sum=(Temp√ó0.6)+(Rain√ó0.4)+2\n",
        "Activation:\n",
        "Output = 1 if Weighted Sum > 20 else 0\n",
        "Case 1:\n",
        " Temp = 70, Rain = 0\n",
        " (70√ó0.6)+(0√ó0.4)+2=42+0+2=44‚áíOutput:¬†1¬†(Go¬†outside)\n",
        "Case 2:\n",
        " Temp = 50, Rain = 1\n",
        " (50√ó0.6)+(1√ó0.4)+2=30+0.4+2=32.4‚áíOutput:¬†1¬†(Go¬†outside)\n",
        "Interpretation: The perceptron suggests going outside in both cases because the weighted sum exceeds 20.\n"
      ],
      "metadata": {
        "id": "eUvzqBSU3Kkp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üåü Exercise 3 : Building a Simple Neural Network with TensorFlow/Keras\n",
        "Build a simple neural network using TensorFlow/Keras to classify handwritten digits from the MNIST dataset. The network should have:\n",
        "\n",
        "One input layer.\n",
        "One hidden layer with 128 neurons and ReLU activation.\n",
        "One output layer with 10 neurons (for 10 classes) and softmax activation.\n",
        "Steps:\n",
        "\n",
        "1. Import TensorFlow and other necessary modules such as layers, models, and utility functions from tensorflow.keras\n",
        "2. Load the MNIST Dataset\n",
        "3. Normalize the Data by scaling the pixel values of the images to the range [0, 1] by dividing by 255.0.\n",
        "4. One-Hot Encode the Labels by converting the digit labels (0‚Äì9) into one-hot encoded vectors.\n",
        "5. To build the Neural Network Model, create a sequential model with the following architecture:\n",
        "\n",
        "A Flatten layer to convert each 28x28 image into a 1D vector.\n",
        "A Dense hidden layer with 128 neurons and ReLU activation.\n",
        "An output Dense layer with 10 neurons and softmax activation (for the 10 classes).\n",
        "6. Compile the model with the following settings:\n",
        "\n",
        "Optimizer: ‚Äòadam‚Äô\n",
        "Loss function: ‚Äòcategorical_crossentropy‚Äô\n",
        "Metrics: [‚Äòaccuracy‚Äô]\n",
        "7. Train the Model and Evaluate it on the test dataset.\n",
        "\n",
        "Dataset: The MNIST dataset is included in TensorFlow/Keras and can be loaded using:\n",
        "\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "hTG2YCKzwOmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Simple NN with MNIST (TensorFlow/Keras)"
      ],
      "metadata": {
        "id": "ghQ__AuGyBtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 2. Normalize\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# 3. One-hot encode\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 4. Build model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 5. Compile\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 6. Train & evaluate\n",
        "model.fit(x_train, y_train, epochs=5, validation_split=0.1)\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "id": "6AbAmF_98lfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üåü Exercise 4 : Forward Propagation Calculation\n",
        "In this exercise, you will manually compute the forward propagation of a simple neural network that predicts house prices based on:\n",
        "\n",
        "Square Footage (x‚ÇÅ)\n",
        "Number of Bedrooms (x‚ÇÇ)\n",
        "We will calculate the output using the following given values:\n",
        "\n",
        "Input Values:\n",
        "    x‚ÇÅ = 2000 (Square Footage)\n",
        "    x‚ÇÇ = 3 (Number of Bedrooms)\n",
        "Initial Weights:\n",
        "    w‚ÇÅ = 0.5 (Weight for Square Footage)\n",
        "    w‚ÇÇ = 0.7 (Weight for Bedrooms)\n",
        "Bias: b = 50,000\n",
        "Activation Function: ReLU (Rectified Linear Unit)\n",
        "Calculate the output value ‚Äúz‚Äù before activation.\n",
        "Apply the ReLU function to compute the final prediction.\n",
        "Interpret the result: What is the predicted house price?"
      ],
      "metadata": {
        "id": "PQuQTUtqx5Q5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4: Forward Propagation Calculation"
      ],
      "metadata": {
        "id": "oYElZyMhzABl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Given:\n",
        "x1 - 2000, x2 - 3\n",
        "w1 = 0.3, w2 = 0.7, b = 50000\n",
        " 1: Compute z\n",
        "z (x1 x w1) + (x2 x w2) + b = (2000 x 0.5) + (3 x 0.7) + 50000 = 1000 + 2.1 + 50000 = 51002.1\n",
        "Step 2: Apply ReLU\n",
        "Output = max(0,z) = 51002.1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0vptYn0487PM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üåü Exercise 5 (optional) : Implementing Forward and Backward Propagation in Python You will code a simple neural network that performs forward propagation and backpropagation for a regression problem (predicting exam scores based on study hours).\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "Initialize input data (features)\n",
        "x = np.array([4, 80]) # 4 hours studied, previous test score: 80\n",
        "\n",
        "Initialize weights and bias\n",
        "w = np.array([0.6, 0.3]) # Initial weights b = 10 # Initial bias\n",
        "\n",
        "Forward Propagation\n",
        "def forward_propagation(x, w, b): z = np.dot(x, w) + b # Weighted sum return z # Linear activation (No ReLU here, it's a regression task)\n",
        "\n",
        "Compute prediction\n",
        "y_pred = forward_propagation(x, w, b) y_true = 85 # Actual exam score\n",
        "\n",
        "Compute Loss (Mean Squared Error)\n",
        "loss = 0.5 * (y_true - y_pred) ** 2\n",
        "\n",
        "Compute Gradients\n",
        "grad_w = -(y_true - y_pred) * x # Partial derivatives with respect to weights grad_b = -(y_true - y_pred) # Partial derivative with respect to bias\n",
        "\n",
        "Update Weights and Bias\n",
        "learning_rate = 0.01 w_new = w - learning_rate * grad_w b_new = b - learning_rate * grad_b\n",
        "\n",
        "Print Results\n",
        "print(\"Initial Prediction:\", y_pred) print(\"Loss:\", loss) print(\"Updated Weights:\", w_new) print(\"Updated Bias:\", b_new)\n",
        "\n",
        "Run the code and observe how the weights and bias update. Explain why updating weights using gradient descent reduces the error. Modify the initial weights or learning rate and see how it affects learning."
      ],
      "metadata": {
        "id": "TeJfEm3ZzO61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Forward & Backward Propagation"
      ],
      "metadata": {
        "id": "KBw8A4kiCsYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([4, 80])\n",
        "w = np.array([0.6, 0.3])\n",
        "b = 10\n",
        "y_true = 85\n",
        "\n",
        "# Forward\n",
        "z = np.dot(x, w) + b\n",
        "loss = 0.5 * (y_true - z)**2\n",
        "\n",
        "# Gradients\n",
        "grad_w = -(y_true - z) * x\n",
        "grad_b = -(y_true - z)\n",
        "\n",
        "# Update\n",
        "learning_rate = 0.01\n",
        "w_new = w - learning_rate * grad_w\n",
        "b_new = b - learning_rate * grad_b\n",
        "\n",
        "print(\"Initial Prediction:\", z)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Updated Weights:\", w_new)\n",
        "print(\"Updated Bias:\", b_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSBn2PokCvsi",
        "outputId": "40ca1afc-c095-4c25-a2cf-2f612c5ae661"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Prediction: 36.4\n",
            "Loss: 1180.98\n",
            "Updated Weights: [ 2.544 39.18 ]\n",
            "Updated Bias: 10.486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Explanation: Gradient descent updates parameters in the direction that reduces loss (error). Repeating this improves predictions."
      ],
      "metadata": {
        "id": "Jw-frK_TDcpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "üåü Exercise 6 (optional) : Visualizing Predictions on the MNIST Dataset\n",
        "Train a simple neural network using TensorFlow/Keras on the MNIST dataset. After training, visualize some of the predictions made by the model.\n",
        "\n",
        "Dataset: The MNIST dataset is included in TensorFlow/Keras.\n",
        "\n",
        "Here are the steps for this exercise :\n",
        "\n",
        "0. Import Required Libraries : Import TensorFlow, NumPy, Matplotlib, and other necessary Keras modules.\n",
        "1. Load the MNIST dataset\n",
        "2. Normalize the data : Scale the pixel values to the range [0, 1].\n",
        "3. One-hot encode the labels : Convert the class labels (digits 0‚Äì9) into one-hot encoded vectors.\n",
        "4. Build the model : Create a model with a Flatten layer to convert each image to a vector, a dense layer with 128 neurons and ReLU activation and an output Dense layer with 10 neurons and softmax activation.\n",
        "5. Compile the model using the following settings:\n",
        "\n",
        "Optimizer: ‚Äòadam‚Äô\n",
        "Loss: ‚Äòcategorical_crossentropy‚Äô\n",
        "Metric: ‚Äòaccuracy‚Äô\n",
        "6. Fit the model on the training data\n",
        "7. Make predictions : Use the trained model to predict the labels of the test images\n",
        "8. Visualize some predictions : Display a few test images alongside the predicted labels using Matplotlib\n",
        "\n"
      ],
      "metadata": {
        "id": "SB7jF-UGv76f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6: Visualizing Predictions (MNIST)"
      ],
      "metadata": {
        "id": "mizS-aa9Dst3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Import required dependencies"
      ],
      "metadata": {
        "id": "EINGrFGWMLOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "cg0kDP0JLQQj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load the Mnist dataset"
      ],
      "metadata": {
        "id": "IYwRffI-MeAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "0FKC6t22Lezr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Normalize the data"
      ],
      "metadata": {
        "id": "gYp4ejKkLqcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n"
      ],
      "metadata": {
        "id": "s9eZyqhILk1D"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. One-hot encode the labels"
      ],
      "metadata": {
        "id": "k_eFf1RgMvkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_encoded = to_categorical(y_train, 10)\n",
        "y_test_encoded = to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "id": "CGPMCwa9Lx5b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Build the model"
      ],
      "metadata": {
        "id": "no5I4jX-NCuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIkVREtwNHQS",
        "outputId": "79cb503b-b7ae-4c57-e2dd-12fa1eebee9a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Compile the model"
      ],
      "metadata": {
        "id": "V-WhsP2tNeDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "fMw3WqGiNtGM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Fit the model"
      ],
      "metadata": {
        "id": "ge6TAAWANysv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train_encoded, epochs=5, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMqR5AYBOGcH",
        "outputId": "b1cff1c9-dca6-45fd-c0d7-8f45f03c3580"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8715 - loss: 0.4585 - val_accuracy: 0.9667 - val_loss: 0.1245\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1323 - val_accuracy: 0.9703 - val_loss: 0.1016\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9748 - loss: 0.0841 - val_accuracy: 0.9767 - val_loss: 0.0817\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0593 - val_accuracy: 0.9792 - val_loss: 0.0801\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0464 - val_accuracy: 0.9777 - val_loss: 0.0815\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7982c7c86d50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions"
      ],
      "metadata": {
        "id": "ZiNhlc88OILE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)  # Shape: (10000, 10)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqxzNnvZOH3U",
        "outputId": "8ef397d9-0296-45bb-af8b-684d8cfaebcb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Visualize Predictions"
      ],
      "metadata": {
        "id": "HEoC-_6KOHao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(images, labels_true, labels_pred, num=10):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(num):\n",
        "        plt.subplot(2, num//2, i+1)\n",
        "        plt.imshow(images[i], cmap='gray')\n",
        "        plt.title(f\"True: {labels_true[i]}\\nPred: {labels_pred[i]}\")\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Show 10 predictions\n",
        "plot_predictions(x_test, y_test, predicted_labels, num=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "gw140kGePC-s",
        "outputId": "28b5b2e6-aa20-48ef-f74b-503026830057"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**:\n",
        "\n",
        "You trained a simple 2-layer neural network.\n",
        "\n",
        "Made predictions on test data.\n",
        "\n",
        "Displayed a few predictions along with the actual digits."
      ],
      "metadata": {
        "id": "Rj-3fk_fPDrO"
      }
    }
  ]
}