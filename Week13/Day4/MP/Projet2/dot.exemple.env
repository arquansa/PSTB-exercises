# Backend utilisé pour le LLM (ollama ou groq)
LLM_BACKEND=ollama

# Modèle à utiliser avec Ollama (ex: llama3, mistral, etc.)
OLLAMA_MODEL=llama3
